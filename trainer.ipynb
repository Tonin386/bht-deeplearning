{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Waldo using AI\n",
    "#### Where is Waldo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import cupy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from IPython.display import clear_output\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "from AI_model import WaldoRecognizer #Local file\n",
    "\n",
    "seed = 300900\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device(\"cuda:0\")\n",
    "    torch.cuda.set_device(\"cuda:0\")\n",
    "    device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaldoDataset(Dataset): #Our dataset class\n",
    "    def __init__(self):\n",
    "        self.waldo_folder = \"Data/Waldo\"\n",
    "        self.notWaldo_folder = \"Data/NotWaldo\"\n",
    "        self.image_files = [(os.path.join(self.waldo_folder, f), 1) for f in os.listdir(self.waldo_folder)] + [(os.path.join(self.notWaldo_folder, f), 0) for f in os.listdir(self.notWaldo_folder)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Image:\n",
    "        image = Image.open(self.image_files[idx][0])\n",
    "\n",
    "        to_tensor = transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),          # Random horizontal flip\n",
    "            # transforms.RandomVerticalFlip(),            # Random vertical flip\n",
    "            # transforms.RandomRotation(30),              # Random rotation within 30 degrees\n",
    "            # transforms.RandomGrayscale(p=0.2),          # Convert image to grayscale with a probability of 20%\n",
    "            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5),  # Random perspective transformation\n",
    "            # transforms.RandomResizedCrop(size=64, scale=(0.95, 1.0)),  # Random resized crop\n",
    "            # transforms.RandomApply([transforms.GaussianBlur(kernel_size=5)], p=0.5),  # Random Gaussian blur\n",
    "            transforms.ToTensor(),                      # Convert to tensor\n",
    "            # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet means and stds\n",
    "            transforms.Normalize(mean=[0] * 3, std=[1] * 3)  # Normalize with Normal distribution means and stds\n",
    "        ])\n",
    "        \n",
    "        return to_tensor(image), self.image_files[idx][1]\n",
    "    \n",
    "    def getLabel(self, idx):\n",
    "        return self.image_files[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15,6))\n",
    "    to_image = transforms.ToPILImage()\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        axes[i].imshow(to_image(images[i][0]))\n",
    "        axes[i].set_title(f\"Waldo : {images[i][1]}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaldoDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.randint(0, len(dataset), 5, dtype='int')\n",
    "images = [dataset[int(i)] for i in random_array]\n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  2 ** 6\n",
    "print(batch_size)\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=seed)\n",
    "train_indices, valid_indices = train_test_split(train_indices, test_size=0.4, random_state=seed)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = WaldoRecognizer().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5\n",
    "counter = 0\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "# momentum = 0.95 # Used with SGD\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "step_size = 2\n",
    "gamma = 0.75\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "epochs = 20\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    network.train()\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\") as t:\n",
    "        for data, target in t:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            data = data.to(device)\n",
    "            target_tensor = target.clone().detach()\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = loss_function(output, target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            accuracy = (correct / total)\n",
    "            train_accuracies.append(accuracy)\n",
    "\n",
    "            t.set_postfix(current_loss=loss.item(), accuracy=accuracy)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            fig, ax1 = plt.subplots()\n",
    "\n",
    "            color = 'tab:red'\n",
    "            ax1.set_xlabel('Iterations')\n",
    "            ax1.set_ylabel('Loss', color=color)\n",
    "            ax1.plot(train_losses, label='Training Loss', color=color)\n",
    "            ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            color = 'tab:blue'\n",
    "            ax2.set_ylabel('Accuracy', color=color)\n",
    "            ax2.plot(train_accuracies, label='Training Accuracy', color=color)\n",
    "            ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.title('Dynamic Loss and Accuracy Plot')\n",
    "            plt.show()\n",
    "\n",
    "    network.eval()  \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(), tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\") as v:\n",
    "        for data, target in v:\n",
    "            data = data.to(device)\n",
    "            output = network(data)  \n",
    "            target_tensor = target.clone().detach()\n",
    "            loss = loss_function(output, target_tensor)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            v.set_postfix(val_accuracy=(correct / total))\n",
    "\n",
    "    val_loss /= len(valid_loader.dataset)  \n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0  \n",
    "        torch.save(network.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(f'Early stopping at epoch {epoch+1}, best validation loss: {best_val_loss}')\n",
    "        break\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Val Accuracy: {(100 * correct / total):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_guess = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "for data, target in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        output = network(data)\n",
    "        target_tensor = target.clone().detach()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        good_guess += (predicted == target).sum().item()\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        target = target_tensor.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            img = data[i].cpu().numpy().transpose((1, 2, 0))\n",
    "\n",
    "            predictions.append((img, predicted[i], target[i]))\n",
    "\n",
    "print(\"%.4f%% of accuracy for this model.\" % (good_guess / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(20, 5))\n",
    "\n",
    "    for i, (image, prediction, target) in enumerate(images):\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Predicted: {prediction} \\n Target: {target}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = random.sample(predictions, 10)\n",
    "\n",
    "display_images(random_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
